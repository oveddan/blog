    <!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Dan Oved&#39;s Blog">
    <meta name="description" content="Connecting the digital with the analog world @ ITP">
    <meta property="og:title" content="Predicting Gaze in Python with the Eye Tracking for Everyone Neural Network  - Dan Oved's blog" />
    <meta property="og:description" content="" />
    
      
        <meta property="og:image" content="http://www.danioved.com/blog/images/gaze/testing_model/testing_model_featured.jpg" />
      
    
    

    
      <meta property="og:updated_time" content="2017-11-13T22:21:18-05:00"/>
    
    <meta name="generator" content="Hugo 0.35" />
    <title>Predicting Gaze in Python with the Eye Tracking for Everyone Neural Network &middot; Dan Oved&#39;s Blog</title>
    <link rel="shortcut icon" href="http://www.danioved.com/blog/images/favicon.ico">
    <link rel="stylesheet" href="http://www.danioved.com/blog/css/style.css">
    <link rel="stylesheet" href="http://www.danioved.com/blog/css/highlight.css">
    
    <link rel="stylesheet" href="http://www.danioved.com/blog//css/style-custom.css">
    

    
    <link rel="stylesheet" href="http://www.danioved.com/blog/css/font-awesome.min.css">
    

    
  </head>

    <body>
       <nav class="main-nav">
	
	
		<a href='http://www.danioved.com/blog/'> <span class="arrow">←</span>Home</a>
	
	<a href='http://www.danioved.com/blog/posts'>Archive</a>
	<a href='http://www.danioved.com/blog/tags'>Tags</a>
  

	

	
</nav>


        <section id="wrapper">
            <article class="post">
                <header>
                    <h1>
                        
                          
                            Presence -
                          
                        
                        Predicting Gaze in Python with the Eye Tracking for Everyone Neural Network
                    </h1>
                    <h2 class="headline">
                    Nov 13, 2017 22:21
                    · 722 words
                    · 4 minutes read
                      <span class="tags">
                      
                      
                          
                              <a href="http://www.danioved.com/blog/tags/presence">Presence</a>
                          
                              <a href="http://www.danioved.com/blog/tags/digital-fabrication">Digital Fabrication</a>
                          
                              <a href="http://www.danioved.com/blog/tags/physical-computing">Physical Computing</a>
                          
                              <a href="http://www.danioved.com/blog/tags/usability-testing">Usability Testing</a>
                          
                      
                      
                      </span>
                      
                        

<nav id="post-nav">
  <div class='next-and-previous'>
    
      <span class="prev">
        <a href="/blog/posts/presence/concepts-and-play-testing/">
          <span class="arrow">←</span> Previous post for Presence
        </a>
      </span>
    
    
      <span class="next">
        <a href="/blog/posts/presence/design-bom-schematics/">
           Next post for Presence <span class="arrow">→</span>
        </a>
      </span>
    
  </div>
</nav>


                      
                    </h2>
                </header>
                
                <section id="post-body">
                    

<p><strong><a href="https://github.com/oveddan/gaze/blob/712d776af2cdd69f51c8dc8fd7893d6a0c4ba434/notebooks/Predicting%20Gaze%20with%20Eye%20Tracking%20for%20Everyone.ipynb">View the ipython notebook with the code here</a></strong></p>

<p>My next goal for <a href="/blog/posts/presence/
">Presence</a> was to try to get eye gaze prediction working using the <a href="http://gazecapture.csail.mit.edu/index.php">Eye Tracking for Everyone</a> model.  I  wanted to get it working in Python so that it would be platform agnostic; the idea would be to eventually get this working on any computer with a webcam and decent GPU.  The ultimate deployment would be on the <a href="http://www.nvidia.com/object/embedded-systems-dev-kits-modules.html">NVidia Jetson TX2</a>, a single-board computer with a powerful GPU and support for six camera inputs.</p>

<p>For the neural network framework I stuck with caffe since that&rsquo;s what the model is published in.   I struggled for days but finally setup Ubuntu with caffe and cuda on my macbook pro, which has a basic <em>NVIDIA GeForce GT 650M</em> graphics card.</p>


<figure >
    <a href="http://gazecapture.csail.mit.edu/cvpr2016_gazecapture.pdf">
        <img src="/blog/images/gaze/proposal/convnet.png" alt="The convolution neural network architecture.  See the research paper for details." />
    </a>
    
    <figcaption>
        <p>
        The convolution neural network architecture.  See the research paper for details.
        
            
        
        </p> 
    </figcaption>
    
</figure>


<p>I used OpenCV to extract the face and eye features, and calculated the 25x25 face grid with code from  <a href="https://github.com/CSAILVision/GazeCapture/blob/master/code/faceGridFromFaceRect.m">faceGridFromRect.m</a> that I converted to python.  I then loaded their model, and fed the inputs through the network.</p>

<p>For all pictures tested I used the selfie camera in portrait mode on an IPhone 8. Since the network outputs the distance from the camera in cm, I could convert this to pixel space on the screen based on the resolution of the pictures and the physical dimensions of the phone.</p>

<p><a href="https://github.com/oveddan/gaze/blob/2c4ad08e8ba75f9a61f9448d3a25aaf5783a6e98/notebooks/Predicting%20Gaze%20with%20Gaze%20Capture%20for%20Everyone.ipynb">View the ipython notebook with all of the code here</a></p>

<h1 id="results">Results</h1>

<p><strong>For each picture the blue dot is where the camera was, and the red dot is where the gaze was predicted to be.</strong> The blue and green square are where the faces and eyes are detected with open cv correspondingly.</p>

<p>
<figure >
    
        <img src="/blog/images/gaze/testing_model/gaze_with_good_result_2.jpg" />
    
    
</figure>


<figure >
    
        <img src="/blog/images/gaze/testing_model/looking_down.jpg" />
    
    
</figure>


<figure >
    
        <img src="/blog/images/gaze/testing_model/gaze_with_two_people.jpg" alt="Multiple people and gazes" />
    
    
    <figcaption>
        <p>
        Multiple people and gazes
        
            
        
        </p> 
    </figcaption>
    
</figure>


<figure >
    
        <img src="/blog/images/gaze/testing_model/gaze_with_good_result_3.jpg" />
    
    
</figure>


<figure >
    
        <img src="/blog/images/gaze/testing_model/looking_at_camera.jpg" alt="I told him to look at the camera when taking this." />
    
    
    <figcaption>
        <p>
        I told him to look at the camera when taking this.
        
            
        
        </p> 
    </figcaption>
    
</figure>
</p>


<figure >
    
        <img src="/blog/images/gaze/testing_model/gaze_with_bad_result.jpg" alt="A bad prediction" />
    
    
    <figcaption>
        <p>
        A bad prediction
        
            
        
        </p> 
    </figcaption>
    
</figure>


<h1 id="performance">Performance</h1>

<p>I tried testing the network on my Macbook Pro&rsquo;s GPU which has 1 gb of ram, but got the Cuda error that there was not enough memory.  On the CPU, testing the network takes about 2.2s.</p>

<p>I then setup Ubuntu, caffe, and cuda on my home gaming pc which is an Alienware X51 and has a GTX 970 with 4 gb of ram. On this setup, it was able to run on the GPU and
that step around 100 ms.  The bottleneck ended up being the opencv detection part, which takes about 0.5s.</p>

<p>The goal is to do real-time gaze detection.  A total runtime of around 0.6 seconds to detect gaze is acceptable for the installation with physical motors, as it is enough time for the motors to change to reflect the new gaze.</p>

<p>To lower the runtime, I plan on optimizing the OpenCV face and eye detection to perform faster.  I would also want to experiment with using a neural network based face detector such as <a href="https://github.com/cmusatyalab/openface">OpenFace</a>.</p>

<p>Also, in the research paper they say they were able to compress the model and run it in real-time on an IPhone.  This model is not available on the github page.  I&rsquo;m going to ask the researchers for this compressed version so that it could run quickly on less demanding gpus such as my Macbook Pro&rsquo;s.</p>

<h1 id="conclusion-next-work">Conclusion &amp; Next Work</h1>

<p>I&rsquo;m thrilled with this experiment as for the most part the results came out pretty accurate, and I&rsquo;m more confident now this can be used to predict gaze for the installation.     The neural network outputs the x and y distance from the camera in centimeters, which is easily usable for a physical installation where we know how far everything is from the camera.</p>

<p>I need to test how well this would work when gazing at a bigger space than just the area round the screen.  This accuracy will determine how large
the final installation will be, as if there is a high error rate when gazing far away from the camera, then the experience will suffer at those
distances, so it will need to be smaller.</p>

<p>To Dos:</p>

<ul>
<li>Connect to a webcam and detect eyes and gazes in realtime.  Display where the gaze is predicted to be in the physical space of a large monitor.</li>
<li>With OpenCV, determine which is the left and right eye, and feed the proper eye to the proper side of the network.</li>
<li>Try to obtain the compressed model from the researchers, and see how it to run on my Macbook Pro&rsquo;s GPU</li>
</ul>


                    
                      <div id="other-posts">
  <h2>Other posts for <strong>the project Presence<strong /></h2>

  <ul id="other-posts-list">
    
      <li><a href="/blog/posts/presence/fabricating-the-kinetic-sculpture/">Fabricating the Kinetic Sculpture</a></li>
    
      <li><a href="/blog/posts/presence/fabricating-the-prototype/">Fabricating the Prototype</a></li>
    
      <li><a href="/blog/posts/presence/design-bom-schematics/">Physical Design, Bill of Materials and Schematics</a></li>
    
      <li><a href="/blog/posts/presence/predicting-gaze-with-the-model/">Predicting Gaze in Python with the Eye Tracking for Everyone Neural Network</a></li>
    
      <li><a href="/blog/posts/presence/concepts-and-play-testing/">Concepts and Play Testing</a></li>
    
      <li><a href="/blog/posts/presence/proposal/">Presence - Proposal</a></li>
    
  </ul>
</div>

                    
                </section>
            </article>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'danoved'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://github.com/oveddan">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.instagram.com/stangogh/">
        <i class="fa fa-instagram"></i>
    </a>
    


</div>

    
    <p class="small">
    
       © Copyright 2018 <i class="fa fa-heart" aria-hidden="true"></i> Dan Oved&#39;s Blog
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="http://www.danioved.com/blog/js/jquery-2.2.4.min.js"></script>
<script src="http://www.danioved.com/blog/js/main.js"></script>
<script src="http://www.danioved.com/blog/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-106896744-1', 'auto');
ga('send', 'pageview');
</script>





    </body>
</html>
