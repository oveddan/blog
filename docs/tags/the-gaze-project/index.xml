<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Gaze Project on Dan Oved&#39;s Blog</title>
    <link>https://oveddan.github.io/blog/tags/the-gaze-project/</link>
    <description>Recent content in The Gaze Project on Dan Oved&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 13 Nov 2017 22:21:18 -0500</lastBuildDate>
    
	<atom:link href="https://oveddan.github.io/blog/tags/the-gaze-project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Predicting Gaze in Python with the Eye Tracking for Everyone Model</title>
      <link>https://oveddan.github.io/blog/posts/gaze/predicting-gaze-with-the-model/</link>
      <pubDate>Mon, 13 Nov 2017 22:21:18 -0500</pubDate>
      
      <guid>https://oveddan.github.io/blog/posts/gaze/predicting-gaze-with-the-model/</guid>
      <description>View the ipython notebook with the code here
My next goal was to try to get eye gaze prediction working using the Eye Tracking for Everyone model. I wanted to get it working in Python so that it would be platform agnostic; the idea would be to eventually get this working on any computer with a webcam and decent GPU. The ultimate deployment would be on the NVidia Jetson TX2, a single-board computer with a powerful GPU and support for six camera inputs.</description>
    </item>
    
    <item>
      <title>The Gaze Project - Play Testing</title>
      <link>https://oveddan.github.io/blog/posts/gaze/play-testing/</link>
      <pubDate>Tue, 07 Nov 2017 20:16:51 -0500</pubDate>
      
      <guid>https://oveddan.github.io/blog/posts/gaze/play-testing/</guid>
      <description>For Intro to Physical Computing this week, we were to play test our final project with our classmates.
For the Gaze Project, I set up the following for the test:
Assumptions  Initially - people will try to follow the animation with their eyes, but they will notice that doing that causes it to go away. They will eventually learn to focus on one point and see the animation grow with their peripherals.</description>
    </item>
    
    <item>
      <title>The Gaze Project - Proposal</title>
      <link>https://oveddan.github.io/blog/posts/gaze/proposal/</link>
      <pubDate>Tue, 31 Oct 2017 22:55:41 -0400</pubDate>
      
      <guid>https://oveddan.github.io/blog/posts/gaze/proposal/</guid>
      <description>This is the proposal for the Gaze Project, an art piece that is activated the longer and the more people gaze directly at it. It would encourage being present and engaged, and connect the fellow participants with each other over moments of mindfulness. This will be my final project for Intro to Physical Computing and Design for Digital Fabrication.
I will use small cameras and computer vision to detect the quantify of people present and how many of them are gazing at a specific point, and reveal parts of the piece using motors and other physical controls.</description>
    </item>
    
  </channel>
</rss>